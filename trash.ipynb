{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize import tokenize, COMMENT, STRING, TokenInfo\n",
    "from pathlib import Path\n",
    "from black import lib2to3_parse\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example/example/main.py\n",
      "example/example/__init__.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'example/example/main.py': Node(file_input, [Node(simple_stmt, [Leaf(STRING, '\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"'), Leaf(NEWLINE, '\\n')]), Node(funcdef, [Leaf(NAME, 'def'), Leaf(NAME, 'foo'), Node(parameters, [Leaf(LPAR, '('), Leaf(RPAR, ')')]), Leaf(COLON, ':'), Node(suite, [Leaf(NEWLINE, '\\n'), Leaf(INDENT, ''), Node(simple_stmt, [Leaf(STRING, '\"\"\"Foo example.\\n\\n    TODO: function docstring\\n    \"\"\"'), Leaf(NEWLINE, '\\n')]), Node(simple_stmt, [Leaf(NAME, 'pass'), Leaf(NEWLINE, '\\n')]), Leaf(DEDENT, '')])]), Node(funcdef, [Leaf(NAME, 'def'), Leaf(NAME, 'bar'), Node(parameters, [Leaf(LPAR, '('), Leaf(RPAR, ')')]), Leaf(COLON, ':'), Node(suite, [Leaf(NEWLINE, '\\n'), Leaf(INDENT, ''), Node(simple_stmt, [Leaf(STRING, '\"\"\"Bar.\\n    \"\"\"'), Leaf(NEWLINE, '\\n')]), Node(simple_stmt, [Leaf(NAME, 'pass'), Leaf(NEWLINE, '\\n')]), Leaf(DEDENT, '')])]), Node(simple_stmt, [Node(expr_stmt, [Leaf(NAME, 'BAZ'), Leaf(EQUAL, '='), Leaf(NUMBER, '1')]), Leaf(NEWLINE, '\\n')]), Node(simple_stmt, [Leaf(STRING, '\"\"\"Baz.\"\"\"'), Leaf(NEWLINE, '\\n')]), Leaf(ENDMARKER, '')]),\n",
       " 'example/example/__init__.py': Node(file_input, [Leaf(ENDMARKER, '')])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# black parser\n",
    "\n",
    "file_tokens = {}\n",
    "for _file in Path(\"example/example\").rglob(\"*.py\"):\n",
    "    print(_file)\n",
    "    with open(_file, \"r\") as fp:\n",
    "        file_tokens[str(_file)] = lib2to3_parse(fp.read())\n",
    "\n",
    "file_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example/example/main.py': [TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
       "  TokenInfo(type=3 (STRING), string='\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"', start=(1, 0), end=(4, 3), line='\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(4, 3), end=(4, 4), line='\"\"\"\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(5, 0), end=(5, 1), line='\\n'),\n",
       "  TokenInfo(type=61 (COMMENT), string='# TODO: comment', start=(6, 0), end=(6, 15), line='# TODO: comment\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(6, 15), end=(6, 16), line='# TODO: comment\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(7, 0), end=(7, 1), line='\\n'),\n",
       "  TokenInfo(type=61 (COMMENT), string='# TODO: multiline', start=(8, 0), end=(8, 17), line='# TODO: multiline\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(8, 17), end=(8, 18), line='# TODO: multiline\\n'),\n",
       "  TokenInfo(type=61 (COMMENT), string='#       comment', start=(9, 0), end=(9, 15), line='#       comment\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(9, 15), end=(9, 16), line='#       comment\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(10, 0), end=(10, 1), line='\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(11, 0), end=(11, 1), line='\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='def', start=(12, 0), end=(12, 3), line='def foo():\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='foo', start=(12, 4), end=(12, 7), line='def foo():\\n'),\n",
       "  TokenInfo(type=54 (OP), string='(', start=(12, 7), end=(12, 8), line='def foo():\\n'),\n",
       "  TokenInfo(type=54 (OP), string=')', start=(12, 8), end=(12, 9), line='def foo():\\n'),\n",
       "  TokenInfo(type=54 (OP), string=':', start=(12, 9), end=(12, 10), line='def foo():\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(12, 10), end=(12, 11), line='def foo():\\n'),\n",
       "  TokenInfo(type=5 (INDENT), string='    ', start=(13, 0), end=(13, 4), line='    \"\"\"Foo example.\\n'),\n",
       "  TokenInfo(type=3 (STRING), string='\"\"\"Foo example.\\n\\n    TODO: function docstring\\n    \"\"\"', start=(13, 4), end=(16, 7), line='    \"\"\"Foo example.\\n\\n    TODO: function docstring\\n    \"\"\"\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(16, 7), end=(16, 8), line='    \"\"\"\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='pass', start=(17, 4), end=(17, 8), line='    pass\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(17, 8), end=(17, 9), line='    pass\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(18, 0), end=(18, 1), line='\\n'),\n",
       "  TokenInfo(type=61 (COMMENT), string='# normal comment', start=(19, 0), end=(19, 16), line='# normal comment\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(19, 16), end=(19, 17), line='# normal comment\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(20, 0), end=(20, 1), line='\\n'),\n",
       "  TokenInfo(type=6 (DEDENT), string='', start=(21, 0), end=(21, 0), line='def bar():\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='def', start=(21, 0), end=(21, 3), line='def bar():\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='bar', start=(21, 4), end=(21, 7), line='def bar():\\n'),\n",
       "  TokenInfo(type=54 (OP), string='(', start=(21, 7), end=(21, 8), line='def bar():\\n'),\n",
       "  TokenInfo(type=54 (OP), string=')', start=(21, 8), end=(21, 9), line='def bar():\\n'),\n",
       "  TokenInfo(type=54 (OP), string=':', start=(21, 9), end=(21, 10), line='def bar():\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(21, 10), end=(21, 11), line='def bar():\\n'),\n",
       "  TokenInfo(type=5 (INDENT), string='    ', start=(22, 0), end=(22, 4), line='    \"\"\"Bar.\\n'),\n",
       "  TokenInfo(type=3 (STRING), string='\"\"\"Bar.\\n    \"\"\"', start=(22, 4), end=(23, 7), line='    \"\"\"Bar.\\n    \"\"\"\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(23, 7), end=(23, 8), line='    \"\"\"\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='pass', start=(24, 4), end=(24, 8), line='    pass\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(24, 8), end=(24, 9), line='    pass\\n'),\n",
       "  TokenInfo(type=62 (NL), string='\\n', start=(25, 0), end=(25, 1), line='\\n'),\n",
       "  TokenInfo(type=6 (DEDENT), string='', start=(26, 0), end=(26, 0), line='BAZ = 1\\n'),\n",
       "  TokenInfo(type=1 (NAME), string='BAZ', start=(26, 0), end=(26, 3), line='BAZ = 1\\n'),\n",
       "  TokenInfo(type=54 (OP), string='=', start=(26, 4), end=(26, 5), line='BAZ = 1\\n'),\n",
       "  TokenInfo(type=2 (NUMBER), string='1', start=(26, 6), end=(26, 7), line='BAZ = 1\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(26, 7), end=(26, 8), line='BAZ = 1\\n'),\n",
       "  TokenInfo(type=3 (STRING), string='\"\"\"Baz.\"\"\"', start=(27, 0), end=(27, 10), line='\"\"\"Baz.\"\"\"\\n'),\n",
       "  TokenInfo(type=4 (NEWLINE), string='\\n', start=(27, 10), end=(27, 11), line='\"\"\"Baz.\"\"\"\\n'),\n",
       "  TokenInfo(type=0 (ENDMARKER), string='', start=(28, 0), end=(28, 0), line='')],\n",
       " 'example/example/__init__.py': [TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
       "  TokenInfo(type=0 (ENDMARKER), string='', start=(1, 0), end=(1, 0), line='')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize stream\n",
    "\n",
    "file_tokens = {}\n",
    "\n",
    "for _file in Path(\"example/example\").rglob(\"*.py\"):\n",
    "    with open(_file, \"rb\") as fp:\n",
    "        file_tokens[str(_file)] = list(tokenize(fp.readline))\n",
    "\n",
    "file_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example/example/main.py 1 TokenInfo(type=3 (STRING), string='\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"', start=(1, 0), end=(4, 3), line='\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"\\n')\n",
      "example/example/main.py 4 TokenInfo(type=61 (COMMENT), string='# TODO: comment', start=(6, 0), end=(6, 15), line='# TODO: comment\\n')\n",
      "example/example/main.py 7 TokenInfo(type=61 (COMMENT), string='# TODO: multiline', start=(8, 0), end=(8, 17), line='# TODO: multiline\\n')\n",
      "example/example/main.py 20 TokenInfo(type=3 (STRING), string='\"\"\"Foo example.\\n\\n    TODO: function docstring\\n    \"\"\"', start=(13, 4), end=(16, 7), line='    \"\"\"Foo example.\\n\\n    TODO: function docstring\\n    \"\"\"\\n')\n"
     ]
    }
   ],
   "source": [
    "for _file, tokens in file_tokens.items():\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.type in [COMMENT, STRING] and \"TODO:\" in token.string:\n",
    "            print(_file, i, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Todo:\n",
    "    scope: Optional[str]\n",
    "    content: str\n",
    "    file: Path\n",
    "    start: Tuple[int,int]\n",
    "    end: Tuple[int,int]\n",
    "\n",
    "TODO_REGEX = re.compile(r'.*TODO(:?\\((?P<scope>.*?)\\)){0,1}:(?P<content>.*)', re.M|re.DOTALL)\n",
    "# TODO_REGEX = re.compile(r'.*TODO:(?P<content>.*)', re.M|re.DOTALL)\n",
    "\n",
    "def parse_todo_string(file: Path, token: TokenInfo) -> Optional[Todo]:\n",
    "    if token.type != STRING:\n",
    "        raise ValueError(\"token must be a string!\")\n",
    "    if match := TODO_REGEX.match(token.string):\n",
    "        return Todo(match.groupdict()[\"scope\"], match.groupdict()[\"content\"], file, token.start, token.end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = parse_todo_string(Path(\"example/example/main.py\"), file_tokens[\"example/example/main.py\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Todo(scope=None, content=' module docstring\\n\"\"\"', file=PosixPath('example/example/main.py'), start=(1, 0), end=(4, 3))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 43), match='\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TODO_REGEX.match(file_tokens[\"example/example/main.py\"][1].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\"Example Repo\\n\\nTODO: module docstring\\n\"\"\"'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_tokens[\"example/example/main.py\"][1].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "todo-issues-zBBBAB1F-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
